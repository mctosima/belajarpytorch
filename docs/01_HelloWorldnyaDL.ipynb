{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X1:\n",
      "tensor([0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0])\n",
      "Input X2:\n",
      "tensor([0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0])\n"
     ]
    }
   ],
   "source": [
    "# membuat variabel x berisi nilai boleean berisi 1 atau 0 sebanyak 50 elemen\n",
    "x1 = torch.randint(0, 2, (50,))\n",
    "x2 = torch.randint(0, 2, (50,))\n",
    "print(f\"Input X1:\\n{x1}\")\n",
    "print(f\"Input X2:\\n{x2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0],\n",
      "        [1, 1],\n",
      "        [1, 0],\n",
      "        [0, 0],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [1, 0],\n",
      "        [0, 0],\n",
      "        [1, 0],\n",
      "        [0, 0],\n",
      "        [1, 1],\n",
      "        [1, 0],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 0],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 0],\n",
      "        [1, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 0],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 0],\n",
      "        [1, 1],\n",
      "        [0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# menggabungkan variabel x1 dan x2 menjadi satu variabel x\n",
    "x = torch.stack((x1, x2), dim=1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground-truth Y:\n",
      "tensor([0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0])\n"
     ]
    }
   ],
   "source": [
    "# membuat ground-truth dari input x1 dan x2 yang sudah distack pada x\n",
    "y = x[:, 0] ^ x[:, 1]\n",
    "print(f\"Ground-truth Y:\\n{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(0.8*len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membagi x menjadi train dan testing\n",
    "x_train = x[:train_split]\n",
    "x_test = x[train_split:]\n",
    "\n",
    "# membagi y menjadi train dan testing\n",
    "y_train = y[:train_split]\n",
    "y_test = y[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat model regresi linear\n",
    "class XORModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(2, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # membuat model regresi linear\n",
    "# class XORModel2(pl.LightningModule):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.linear = nn.Linear(2, 2)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "#         self.linear2 = nn.Linear(2, 1)\n",
    "#         self.loss_fn = nn.MSELoss()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.float()\n",
    "#         x = self.linear(x)\n",
    "#         x = self.sigmoid(x)\n",
    "#         x = self.linear2(x)\n",
    "#         x = self.sigmoid(x)\n",
    "#         return x\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         return torch.optim.SGD(self.parameters(), lr=0.1, momentum=0.9)\n",
    "    \n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         x, y = batch\n",
    "#         y_hat = self(x)\n",
    "#         loss = self.loss_fn(y_hat, y.unsqueeze(1).float())\n",
    "#         self.log('train_loss', loss)\n",
    "#         return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # trainer\n",
    "# trainer = pl.Trainer(\n",
    "#     max_epochs=1000,\n",
    "#     track_grad_norm=2,\n",
    "#     accelerator='gpu',\n",
    "#     devices=1,\n",
    "#     log_every_n_steps=1,\n",
    "# )\n",
    "\n",
    "# # membuat model\n",
    "# model = XORModel2()\n",
    "\n",
    "# # membuat dataloader\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     torch.utils.data.TensorDataset(x_train, y_train),\n",
    "#     batch_size=50,\n",
    "#     shuffle=True,\n",
    "# )\n",
    "\n",
    "# # training\n",
    "# trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[ 0.3842, -0.1170],\n",
      "        [ 0.5053,  0.0350]])), ('linear.bias', tensor([-0.2968,  0.1043])), ('linear2.weight', tensor([[-0.5254,  0.3724]])), ('linear2.bias', tensor([0.1998]))])\n"
     ]
    }
   ],
   "source": [
    "# create instance\n",
    "model = XORModel()\n",
    "\n",
    "# check state_dict\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 0],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 0],\n",
      "        [1, 1],\n",
      "        [0, 0]])\n",
      "Hasil prediksi:\n",
      "tensor([[0.5416],\n",
      "        [0.5473],\n",
      "        [0.5416],\n",
      "        [0.5428],\n",
      "        [0.5462],\n",
      "        [0.5473],\n",
      "        [0.5462],\n",
      "        [0.5428],\n",
      "        [0.5462],\n",
      "        [0.5428]], grad_fn=<SigmoidBackward0>)\n",
      "Ground-truth:\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# mencoba inferensi dengan input x\n",
    "y_pred = model(x_test)\n",
    "print(f\"Input:\\n{x_test}\")\n",
    "print(f\"Hasil prediksi:\\n{y_pred}\")\n",
    "print(f\"Ground-truth:\\n{y_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape yPred: torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape yPred: {y_pred.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mendefinisikan loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "# epoch\n",
    "epochs = 10000\n",
    "\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "epoch_count = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Loss: 0.240, Test Loss: 0.240\n",
      "Epoch: 100, Loss: 0.240, Test Loss: 0.240\n",
      "Epoch: 150, Loss: 0.239, Test Loss: 0.240\n",
      "Epoch: 200, Loss: 0.239, Test Loss: 0.240\n",
      "Epoch: 250, Loss: 0.239, Test Loss: 0.240\n",
      "Epoch: 300, Loss: 0.238, Test Loss: 0.240\n",
      "Epoch: 350, Loss: 0.238, Test Loss: 0.241\n",
      "Epoch: 400, Loss: 0.237, Test Loss: 0.241\n",
      "Epoch: 450, Loss: 0.237, Test Loss: 0.241\n",
      "Epoch: 500, Loss: 0.236, Test Loss: 0.241\n",
      "Epoch: 550, Loss: 0.236, Test Loss: 0.242\n",
      "Epoch: 600, Loss: 0.235, Test Loss: 0.242\n",
      "Epoch: 650, Loss: 0.235, Test Loss: 0.243\n",
      "Epoch: 700, Loss: 0.235, Test Loss: 0.243\n",
      "Epoch: 750, Loss: 0.235, Test Loss: 0.244\n",
      "Epoch: 800, Loss: 0.234, Test Loss: 0.244\n",
      "Epoch: 850, Loss: 0.234, Test Loss: 0.244\n",
      "Epoch: 900, Loss: 0.234, Test Loss: 0.244\n",
      "Epoch: 950, Loss: 0.233, Test Loss: 0.244\n",
      "Epoch: 1000, Loss: 0.232, Test Loss: 0.243\n",
      "Epoch: 1050, Loss: 0.231, Test Loss: 0.242\n",
      "Epoch: 1100, Loss: 0.227, Test Loss: 0.239\n",
      "Epoch: 1150, Loss: 0.222, Test Loss: 0.234\n",
      "Epoch: 1200, Loss: 0.212, Test Loss: 0.225\n",
      "Epoch: 1250, Loss: 0.197, Test Loss: 0.211\n",
      "Epoch: 1300, Loss: 0.180, Test Loss: 0.195\n",
      "Epoch: 1350, Loss: 0.165, Test Loss: 0.181\n",
      "Epoch: 1400, Loss: 0.154, Test Loss: 0.171\n",
      "Epoch: 1450, Loss: 0.146, Test Loss: 0.163\n",
      "Epoch: 1500, Loss: 0.139, Test Loss: 0.156\n",
      "Epoch: 1550, Loss: 0.134, Test Loss: 0.151\n",
      "Epoch: 1600, Loss: 0.130, Test Loss: 0.147\n",
      "Epoch: 1650, Loss: 0.127, Test Loss: 0.144\n",
      "Epoch: 1700, Loss: 0.124, Test Loss: 0.141\n",
      "Epoch: 1750, Loss: 0.121, Test Loss: 0.138\n",
      "Epoch: 1800, Loss: 0.119, Test Loss: 0.136\n",
      "Epoch: 1850, Loss: 0.117, Test Loss: 0.133\n",
      "Epoch: 1900, Loss: 0.114, Test Loss: 0.131\n",
      "Epoch: 1950, Loss: 0.112, Test Loss: 0.128\n",
      "Epoch: 2000, Loss: 0.108, Test Loss: 0.124\n",
      "Epoch: 2050, Loss: 0.103, Test Loss: 0.118\n",
      "Epoch: 2100, Loss: 0.092, Test Loss: 0.105\n",
      "Epoch: 2150, Loss: 0.070, Test Loss: 0.080\n",
      "Epoch: 2200, Loss: 0.045, Test Loss: 0.051\n",
      "Epoch: 2250, Loss: 0.029, Test Loss: 0.032\n",
      "Epoch: 2300, Loss: 0.020, Test Loss: 0.022\n",
      "Epoch: 2350, Loss: 0.015, Test Loss: 0.016\n",
      "Epoch: 2400, Loss: 0.012, Test Loss: 0.013\n",
      "Epoch: 2450, Loss: 0.010, Test Loss: 0.011\n",
      "Epoch: 2500, Loss: 0.008, Test Loss: 0.009\n",
      "Epoch: 2550, Loss: 0.007, Test Loss: 0.008\n",
      "Epoch: 2600, Loss: 0.007, Test Loss: 0.007\n",
      "Epoch: 2650, Loss: 0.006, Test Loss: 0.006\n",
      "Epoch: 2700, Loss: 0.005, Test Loss: 0.006\n",
      "Epoch: 2750, Loss: 0.005, Test Loss: 0.005\n",
      "Epoch: 2800, Loss: 0.004, Test Loss: 0.005\n",
      "Epoch: 2850, Loss: 0.004, Test Loss: 0.004\n",
      "Epoch: 2900, Loss: 0.004, Test Loss: 0.004\n",
      "Epoch: 2950, Loss: 0.004, Test Loss: 0.004\n",
      "Epoch: 3000, Loss: 0.003, Test Loss: 0.004\n",
      "Epoch: 3050, Loss: 0.003, Test Loss: 0.003\n",
      "Epoch: 3100, Loss: 0.003, Test Loss: 0.003\n",
      "Epoch: 3150, Loss: 0.003, Test Loss: 0.003\n",
      "Epoch: 3200, Loss: 0.003, Test Loss: 0.003\n",
      "Epoch: 3250, Loss: 0.003, Test Loss: 0.003\n",
      "Epoch: 3300, Loss: 0.002, Test Loss: 0.003\n",
      "Epoch: 3350, Loss: 0.002, Test Loss: 0.002\n",
      "Epoch: 3400, Loss: 0.002, Test Loss: 0.002\n",
      "Epoch: 3450, Loss: 0.002, Test Loss: 0.002\n",
      "Epoch: 3500, Loss: 0.002, Test Loss: 0.002\n",
      "Epoch: 3550, Loss: 0.002, Test Loss: 0.002\n",
      "Epoch: 3600, Loss: 0.002, Test Loss: 0.002\n",
      "Epoch: 3650, Loss: 0.002, Test Loss: 0.002\n",
      "Epoch: 3700, Loss: 0.002, Test Loss: 0.002\n",
      "Epoch: 3750, Loss: 0.002, Test Loss: 0.002\n",
      "Epoch: 3800, Loss: 0.002, Test Loss: 0.002\n",
      "Epoch: 3850, Loss: 0.002, Test Loss: 0.002\n",
      "Epoch: 3900, Loss: 0.002, Test Loss: 0.002\n",
      "Epoch: 3950, Loss: 0.002, Test Loss: 0.002\n",
      "Epoch: 4000, Loss: 0.001, Test Loss: 0.002\n",
      "Epoch: 4050, Loss: 0.001, Test Loss: 0.002\n",
      "Epoch: 4100, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 4150, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 4200, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 4250, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 4300, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 4350, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 4400, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 4450, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 4500, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 4550, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 4600, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 4650, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 4700, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 4750, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 4800, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 4850, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 4900, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 4950, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5000, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5050, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5100, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5150, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5200, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5250, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5300, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5350, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5400, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5450, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5500, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5550, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5600, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5650, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5700, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5750, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5800, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5850, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5900, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 5950, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6000, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6050, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6100, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6150, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6200, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6250, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6300, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6350, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6400, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6450, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6500, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6550, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6600, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6650, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6700, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6750, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6800, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6850, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6900, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 6950, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 7000, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 7050, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 7100, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 7150, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 7200, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 7250, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 7300, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 7350, Loss: 0.001, Test Loss: 0.001\n",
      "Epoch: 7400, Loss: 0.000, Test Loss: 0.001\n",
      "Epoch: 7450, Loss: 0.000, Test Loss: 0.001\n",
      "Epoch: 7500, Loss: 0.000, Test Loss: 0.001\n",
      "Epoch: 7550, Loss: 0.000, Test Loss: 0.001\n",
      "Epoch: 7600, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 7650, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 7700, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 7750, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 7800, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 7850, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 7900, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 7950, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8000, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8050, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8100, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8150, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8200, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8250, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8300, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8350, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8400, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8450, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8500, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8550, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8600, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8650, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8700, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8750, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8800, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8850, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8900, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 8950, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9000, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9050, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9100, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9150, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9200, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9250, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9300, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9350, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9400, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9450, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9500, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9550, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9600, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9650, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9700, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9750, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9800, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9850, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9900, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 9950, Loss: 0.000, Test Loss: 0.000\n",
      "Epoch: 10000, Loss: 0.000, Test Loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "    # training\n",
    "    y_pred = model(x_train)\n",
    "    y_train = y_train.float()\n",
    "    loss = loss_fn(y_pred, y_train.unsqueeze(1))\n",
    "\n",
    "    # backward\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # testing\n",
    "    with torch.no_grad():\n",
    "        y_test_pred = model(x_test)\n",
    "        y_test = y_test.float()\n",
    "        test_loss = loss_fn(y_test_pred, y_test.unsqueeze(1))\n",
    "\n",
    "    # print loss only 3 digit after comma. Log every 500 epoch\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f\"Epoch: {epoch+1}, Loss: {loss.item():.3f}, Test Loss: {test_loss.item():.3f}\")\n",
    "\n",
    "    # append loss\n",
    "    train_loss_list.append(loss.item())\n",
    "    test_loss_list.append(test_loss.item())\n",
    "    epoch_count.append(epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[1, 1]])\n",
      "Hasil prediksi:\n",
      "tensor([[0.0146]], grad_fn=<SigmoidBackward0>)\n",
      "Ground-truth:\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "# mencoba inferensi dengan input yang diberikan pengguna\n",
    "x_user = torch.tensor([[1, 1]])\n",
    "y_truth = x_user[:, 0] ^ x_user[:, 1]\n",
    "y_pred = model(x_user)\n",
    "\n",
    "print(f\"Input:\\n{x_user}\")\n",
    "print(f\"Hasil prediksi:\\n{y_pred}\")\n",
    "print(f\"Ground-truth:\\n{y_truth}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch112_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "176e86e6e21052ff89627b8e89e4f48b2aef17a8606feae6b75037084a2df81a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
